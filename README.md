# ğŸ’° Finance Intelligence Assistant (LLM + RAG)

A **local-first, privacy-preserving Finance Intelligence Assistant** built using
Retrieval-Augmented Generation (RAG), open-source embeddings, and a locally hosted LLM
(Mistral-7B via Ollama).

This system integrates multiple finance-related capabilitiesâ€”banking FAQs and
investment advisoryâ€”into a **single conversational interface** with **intent-aware
query routing**.

---

## ğŸš€ Key Features

- âœ… **Local LLM (Mistral-7B via Ollama)** â€” no cloud inference
- âœ… **RAG-based Banking FAQ Assistant**
- âœ… **RAG-based Investment Advisor (case-based reasoning)**
- âœ… **Intent-aware query routing**
- âœ… **Single chat interface (Streamlit UI)**
- âœ… **Vector database persistence using Chroma**
- âœ… **Modular, backend-ready architecture**

---

## ğŸ§  System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User (Streamlit Chat UI)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Intent Classifier â”‚
         â”‚      (LLM)        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FAQ RAG     â”‚   â”‚ Investment    â”‚
â”‚  (BankFAQs)   â”‚   â”‚  RAG (CSV)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   Mistral-7B via    â”‚
      â”‚   Ollama (Local)    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


---

## ğŸ“ Project Structure

```
LLM-RAG_Finance_UseCases/
â”œâ”€â”€ src/                          # Backend & UI source code
â”‚   â”œâ”€â”€ app.py                    # Main CLI-based entry point
â”‚   â”œâ”€â”€ ui.py                     # Streamlit web interface
â”‚   â”œâ”€â”€ main.py                   # Testing script for advisory pipeline
â”‚   â”œâ”€â”€ config.py                 # Central configuration
â”‚   â”œâ”€â”€ llm.py                    # LLM (Ollama) wrapper
â”‚   â”œâ”€â”€ embeddings.py             # Embedding model loader
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                # Data loading & processing
â”‚   â”‚   â”œâ”€â”€ faq_data.py           # Bank FAQ ingestion
â”‚   â”‚   â”œâ”€â”€ investment_data.py    # Investment dataset ingestion
â”‚   â”‚   â””â”€â”€ news_data.py          # News dataset ingestion
â”‚   â”‚
â”‚   â”œâ”€â”€ vectorstore/              # Vector DB management logic
â”‚   â”‚   â”œâ”€â”€ faq_store.py          # FAQ vector DB
â”‚   â”‚   â”œâ”€â”€ investment_store.py   # Investment vector DB
â”‚   â”‚   â””â”€â”€ news_store.py         # News vector DB
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/                # RAG pipelines
â”‚   â”‚   â”œâ”€â”€ faq_qa.py             # FAQ RAG logic
â”‚   â”‚   â”œâ”€â”€ investment_advisor.py # Investment advisory pipeline
â”‚   â”‚   â””â”€â”€ news_qa.py            # News RAG pipeline
â”‚   â”‚
â”‚   â””â”€â”€ router/                   # Query routing
â”‚       â”œâ”€â”€ intent_router.py      # LLM intent classification
â”‚       â””â”€â”€ domain_embeddings.py  # Semantic routing
â”‚
â”œâ”€â”€ vector_store/                 # Persistent ChromaDB data
â”‚   â”œâ”€â”€ faqs/                     # FAQ vector index
â”‚   â”œâ”€â”€ investment/               # Investment vector index
â”‚   â””â”€â”€ investment_news/          # News vector index
â”‚
â”œâ”€â”€ BankFAQs.csv                  # Banking FAQ dataset
â”œâ”€â”€ Finance_data.csv              # Investment preference dataset
â”œâ”€â”€ LLM_+_RAG_for_Finance.ipynb   # Development notebook (V1-V4)
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Project documentation
```


---

## ğŸ“Š Data Sources

- **BankFAQs.csv**
  - ~1,700 real-world banking FAQs
  - Topics: debit/credit cards, OTP, loans, security, procedures

- **Finance_data.csv**
  - Investment preference dataset (Kaggle)
  - Used for case-based investment advice via RAG

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create virtual environment
```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Install & run Ollama
```bash
ollama pull mistral
ollama run mistral
```

### 4ï¸âƒ£ (Optional) Set Hugging Face token
```bash
setx HF_TOKEN "your_huggingface_token"
```

---

## ğŸ–¥ï¸ Run the Application

### CLI mode
```bash
python src/app.py
```

### Streamlit Chat UI
```bash
streamlit run src/ui.py
```

---

## ğŸ§ª Example Queries

### Banking FAQ

```
How do I reset my debit card PIN?
```

### Investment Advice

```
I want to invest in mutual funds for 3 years with moderate risk
```

The system automatically detects intent and routes the query.

---

## ğŸ§© Design Philosophy

- **Local-first & private** â€” no user data leaves the machine
- **Modular pipelines** â€” easy to extend with new domains
- **LLM as reasoning engine, not knowledge base**
- **RAG for grounding & reliability**
- **Simple UX, intelligent backend**

---

## ğŸ›£ï¸ Future Extensions

- Market & news RAG
- Source citation in UI
- FastAPI backend
- Dockerized deployment
- Migration to modern LangChain (RunnableSequence)

---

## ğŸ“Œ Status

- **Current State:** Fully functional multi-domain RAG assistant
- **Target Use:** Learning, demos, and foundation for production systems